
#rule all_local: 
#   input: cov=expand("binning/{group}/C10K_coverage.tsv",group=GROUPS),
#          bins=expand("binning/{group}/clustering_gt500.csv",group=GROUPS)
#          touch=expand("binning/{group}/bin_creation.done",group=GROUPS)


#cut contigs by ORFs and get the bed file
rule cut_contigs:
    input:  fa="assembly/%s/{group}.fasta" % ASSEMBLER,
            gff="annotation/{group}/{group}.gff"
    output: contig="profile/split_c10k/{group}.fasta",
            Contig_bed="annotation/{group}/{group}_C10K_contig.bed"
    shell:  "{SCRIPTS}/Use_orf_to_cut.py {input.fa} {input.gff} > {output.contig}"


rule index_samples_bam:
    input:   "profile/{frags}/{group}/{sample}.sorted.bam",
    output:  "profile/{frags}/{group}/{sample}.sorted.bam.bai",
    message: "Indexing each bam file before coverage calcul"
    threads: THREADS
    shell:   "samtools index {input}"

# use mosdepth to compute coverage by feature on a bed file
rule depth_local:
    input:   sample="profile/{frags}/{group}/{sample}.sorted.bam",
             index="profile/{frags}/{group}/{sample}.sorted.bam.bai",
             bed_file="annotation/{group}/{group}_C10K_contig.bed"
    output:  cov="profile/{frags}/{group}/{sample}.cov",
             gz_cov=temp("profile/{frags}/{group}/{sample}.regions.bed.gz")
    log:     "profile/{frags}/{group}/{sample}.log"
    message: "Calculating depths for {wildcards.frags} from {wildcards.group} across samples"
    threads: min(THREADS,4)
    shell:   """
             mosdepth -t {threads} -n  -b {input.bed_file} profile/{wildcards.frags}/{wildcards.group}/{wildcards.sample} {input.sample}>{log}
             zcat {output.gz_cov} | awk '{{print $5}}'>{output.cov}
             zcat {output.gz_cov} | awk '{{print $4}}'>profile/{wildcards.frags}/{wildcards.group}/header.txt
             rm profile/{wildcards.frags}/{wildcards.group}/{wildcards.sample}.mosdepth.global.dist.txt
             rm profile/{wildcards.frags}/{wildcards.group}/{wildcards.sample}.mosdepth.region.dist.txt
             rm profile/{wildcards.frags}/{wildcards.group}/{wildcards.sample}.regions.bed.gz.csi
             """

# merge all samples 
rule merge:
    input:   samples=expand("profile/scaffolds/{{group}}/{sample}.sorted.bam", sample=SAMPLES),
             cov=expand("profile/scaffolds/{{group}}/{sample}.cov",sample=SAMPLES)
    output:  cov="binning/{group}/C10K_coverage.tsv",
             temp=temp("profile/scaffolds/{group}/{group}_temp.txt")
    params:  tab='\t'.join(SAMPLES),
             space=" ".join(map(lambda x:"profile/scaffolds/{group}/"+x+".cov",SAMPLES))
    shell:   """
             echo {params.space}
             paste {params.space} >{output.temp}
             echo -e 'contig\t'"{params.tab}">{output.cov}
             paste profile/scaffolds/{wildcards.group}/header.txt {output.temp} >> {output.cov}
             """

rule initial_quantity_of_bins:
    # we take a look at all the SCG, take the median over the 36 of them, and multiply that by 10
    input: "annotation/{group}/{group}_SCG.fna"
    output:"annotation/{group}/{group}_nb_ini_bins.txt"
    shell: "{SCRIPTS}/get_num_bin_ini.py {input}>{output}"

#  concoct 
rule concoct:
    input:   cov="binning/{group}/C10K_coverage.tsv",
             fasta="profile/split_c10k/{group}.fasta",
             nb_bin="annotation/{group}/{group}_nb_ini_bins.txt"
    output:  bins="binning/{group}/clustering_gt%d.csv"%MIN_CONTIG_SIZE,
             Data="binning/{group}/original_data_gt%d.csv"%MIN_CONTIG_SIZE             
    params:  mine_contig_size=MIN_CONTIG_SIZE
    threads: THREADS
    shell:   """
             concoct --coverage_file {input.cov} --composition_file {input.fasta} -b binning/{wildcards.group} -c $(<{input.nb_bin}) -l {params} -t {threads}
             """


rule refine:
    input:  bins="binning/{group}/clustering_gt%d.csv"%MIN_CONTIG_SIZE,
            SCG="annotation/{group}/{group}_SCG.fna",
            Data="binning/{group}/original_data_gt%d.csv"%MIN_CONTIG_SIZE
    output: R=temp("binning/{group}/clustering_gt%dR.csv")%MIN_CONTIG_SIZE,
            table="binning/{group}/clustering_gt%d_SCG_table.csv"%MIN_CONTIG_SIZE,
            bins_R="binning/{group}/clustering_refine.csv",
            table_R="binning/{group}/clustering_gt%d_SCG_table_R.csv"%MIN_CONTIG_SIZE
    log:    temp("binning/{group}/clustering.log")
    threads: 1000
    shell:  """ {SCRIPTS}/SCG_in_Bins.py {input.bins} {input.SCG} -t {output.table}
            sed '1d' {input.bins}  > {output.R}
            cd binning/{wildcards.group}
            concoct_refine ../../{output.R} ../../{input.Data} ../../{output.table} -t {threads} &>../../{log}
            cd ../../
            {SCRIPTS}/SCG_in_Bins.py {output.bins_R} {input.SCG} -t {output.table_R}
            """

rule merge_contigs:
    input:   "{path}/clustering_refine.csv",
    output:  "{path}/clustering_gt"+str(MIN_CONTIG_SIZE)+"_merged.csv"
    log:     "{path}/consensus.log"
    threads: THREADS
    shell:   "{SCRIPTS}/Consensus.py {input} >{output} 2>{log}"

rule create_bin_folders:
    input:   bin="binning/{group}/clustering_gt"+str(MIN_CONTIG_SIZE)+"_merged.csv",
             fasta="annotation/{group}/{group}_SCG.fna"
    output:  dynamic("binning/{group}/Bin_{path1}/SCG.fna")
    shell:   "{SCRIPTS}/SCG_in_Bins.py {input.bin} {input.fasta} -f binning/{wildcards.group}/"

