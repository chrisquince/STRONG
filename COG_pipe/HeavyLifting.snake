include: "Common.snake"

import glob
import os

#FIXME shouldn't we start subgraphs folder here?
def bin_paths_by_type(bin_type):
  return [os.path.dirname(path) for path in glob.glob("subgraphs/%s/Bin_*/SCG.fna" % bin_type)]

INIT_BIN_PATHS=bin_paths_by_type("Bin_ini")

#TODO think of a better flag name
rule all:
    input: "subgraphs/Merged_Bin/selected_bins.txt"

rule extract_subgraphs:
    input:   cogs="subgraphs/{bin_type}/{bin}/SCG.fna",
             gfa="assembly/high_res/simplified.gfa"
    output:  touch("subgraphs/{bin_type}/{bin}/subgraph.done")
    log:     "subgraphs/{bin_type}/{bin}/subgraph.log"
    threads: THREADS
    shell:   "{SOFT}/subgraph-extractor -part-seq {input.cogs} -graph {input.gfa} -o $(dirname {output}) -k {ASSEMBLY_K} -t {threads} -cds-len-est {SCG_DATA}/coreCogs.tsv> {log}"

rule create_unitig_profile:
    input: flag="subgraphs/{bin_type}/{bin}/subgraph.done",
           mult_prof="assembly/high_res/simplified.mult_prof"
    output: touch('subgraphs/{bin_type}/{bin}/profile.done')
    shell:  """
            rm -rf $(dirname {input.flag})/*.tsv
            for file in $(dirname {input.flag})/*gfa; do
                stub=${{file%.gfa}}
                awk '/^S/{{print ">"$2"\\n"$3 }}' $file | grep ">" | sed 's/>//g' > $stub.id    
                awk 'FNR==NR {{hash[$1]; next}} $1 in hash' $stub.id {input.mult_prof} > ${{stub}}.tsv
                rm $stub.id
            done
            """

def bin_avg_cov(bin_cov_fn, bin_name):
    with open(bin_cov_fn) as f:
        for l in f:
            #TODO should probably work without strip()
            b, cov = l.strip().split()
            if ("Bin_" + b) == bin_name:
                return cov

    assert False
    return 0
    
#FIXME do I need to specify tmp folder
#TODO refactor? (maybe without a loop)
rule simplify_subgraphs:
    input: bin_cov="subgraphs/{bin_type}/bin_cov.tsv",
           profiles_flag="subgraphs/{bin_type}/{bin}/profile.done"
    output: touch("subgraphs/{bin_type}/{bin}/simplif.done")
    threads: THREADS
    run:
      avg_cov = bin_avg_cov(input[0], wildcards["bin"])
      shell("""
            out=$(dirname {output})/simplif
            rm -rf $out
            mkdir -p $out/tmp
            in=$(dirname {input.profiles_flag})
            echo "HERE " $in
            for g in $in/*gfa; do
                name=$(basename $g .gfa)
                {SOFT}/spades-gsimplifier $g $out/$name --gfa -k {ASSEMBLY_K} -s $in/$name.stops -d $in/$name.deadends -p $in/$name.tsv -c {avg_cov} -read-length {READ_LENGTH} -t {threads} -tmpdir $out/tmp &> $out/$name.log
            done
            """)

rule identify_bins_to_merge:
    input:   expand("{path}/simplif.done", path = INIT_BIN_PATHS)
    #TODO should we put cogs to ignore files within the bin subfolders?
    output:  cogs_to_ignore = "subgraphs/Bin_ini/bin_cogs_to_ignore.tsv",
             bins_to_merge = "subgraphs/Bin_ini/bins_to_merge.tsv"
    params:  folder="subgraphs/Bin_ini"
    #TODO use the input somehow? 
    shell:   "{SCRIPTS}/Common_unitigs.py {params.folder}/'Bin*/simplif/COG*.gfa' 10 {output.bins_to_merge} {output.cogs_to_ignore}"

#TODO review logic and maybe move to scripts / separate into multiple rules
#FIXME normalize variable names and spacing
checkpoint merge_bins:
    input:  merge_plan="subgraphs/Bin_ini/bins_to_merge.tsv",
            contig_assign="binning/clustering_gt%s_merged.csv" % MIN_CONTIG_SIZE
    output: "subgraphs/Merged_Bin/clustering.csv"
    shell:  "{SCRIPTS}/merge_bins.py {input.merge_plan} $(dirname {input.merge_plan}) "
            "{input.contig_assign} $(dirname {output})"

#TODO remove by reusing another snakefile (as discussed with Seb)
rule compute_avg_cov_merged:
    input:   "subgraphs/Merged_Bin/clustering.csv"
    output:  "subgraphs/Merged_Bin/bin_cov.tsv"
    shell:   "{SCRIPTS}/bin_cov.py {input} {output} {ASSEMBLY_K}"

rule flag_bad_cogs:
    input:  "{path}/bin_cogs_to_ignore.tsv",
            "{path}/{bin}/simplif.done"
    output:  touch("{path}/{bin}/selected_cogs.tsv")
    run:
        all_cogs, = glob_wildcards(os.dirname(output[0]) + "/{cog}.gfa")
        #TODO introduce helper function?
        with open(input[0]) as cogs_to_ignore:
            for line in cogs_to_ignore:
                split_line = line.rstrip().split("\t")
                if split_line[0] == wildcards.bin:
                    bad_cogs = {cog for cog in split_line[1:]}
    
                    with open(output[0], "w") as out:
                        #TODO will using sets simplify the code?
                        out.write("\n".join(sorted([cog for cog in all_cogs if cog not in bad_cogs])))
    
                return
            #line for the bin was not found in bin_cog_to_ignore.tsv
            assert False

#TODO review logic
def merged_bins_cogs(wildcards):
    checkpoints.merge_bins.get()
    # since we linked non merged bins in the merged bin folder, bins in that folder are, at that point in time, the correct set of bin to consider. 
    return [binpath+"/selected_cogs.tsv" for binpath in bin_paths_by_type("Merged_Bin")]

rule select_bins_for_strain_analysis:
    input:  merged_bins_cogs
    output: "subgraphs/Merged_Bin/selected_bins.txt"
    message: "Select bins containing sufficient number of COGs"
    run:
      #FIXME magic constant
      # select bin_name only, not full path 
      bins = [os.path.basename(os.path.dirname(cogs_fn)) for cogs_fn in input \
              if len(list(open(selected_cogs_fn).readlines())) >= 10]
      with open(output[0], 'w') as out:
          out.write("\n".join(bins))
