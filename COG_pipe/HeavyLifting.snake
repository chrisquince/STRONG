include: "Common.snake"

import glob
import os

#FIXME move StrainAnalysis out of binning folder

def bin_paths_by_type(bin_type):
  return [os.path.dirname(path) for path in glob.glob("subgraphs/%s/Bin_*/SCG.fna" % bin_type)]

INIT_BIN_PATHS=bin_paths_by_type("Bin_ini")

#TODO think of a better flag name
rule all:
    input "subgraphs/Merged_Bin/selected_bins.txt"

rule extract_subgraphs:
    input:   cogs="subgraphs/{bin_type}/{bin}/SCG.fna",
             gfa="assembly/high_res/simplified.gfa"
    output:  touch("subgraphs/{bin_type}/{bin}/subgraph.done")
    log:     "subgraphs/{bin_type}/{bin}/subgraph.log"
    threads: THREADS
    shell:   "{SOFT}/subgraph-extractor -part-seq {input.cogs} -graph {input.gfa} -o $(dirname {output}) -k {ASSEMBLY_K} -t {threads} -cds-len-est {SCG_DATA}/coreCogs.tsv> {log}"

rule create_unitig_profile:
    input: flag="subgraphs/{bin_type}/{bin}/subgraph.done",
           mult_prof="assembly/high_res/simplified.mult_prof"
    output: touch('subgraphs/{bin_type}/{bin}/profile.done')
    shell:  """
            rm -rf $(dirname {input.flag})/*.tsv
            for file in $(dirname {input.flag})/*gfa; do
                stub=${{file%.gfa}}
                awk '/^S/{{print ">"$2"\\n"$3 }}' $file | grep ">" | sed 's/>//g' > $stub.id    
                awk 'FNR==NR {{hash[$1]; next}} $1 in hash' $stub.id {input.mult_prof} > ${{stub}}.tsv
                rm $stub.id
            done
            """

#FIXME do I need to specify tmp folder
#TODO refactor (maybe without a loop)
rule simplify_subgraphs:
    input: "subgraphs/{bin_type}/{bin}/profile.done"
    output: touch('subgraphs/{bin_type}/{bin}/simplif.done')
    params:
    threads: THREADS
    run:
      BIN_AVG_COV=dict()
      Path="/".join(["subgraphs",wildcards["bin_type"],"bin_cov.tsv"])
      for l in open(Path):
        bin, cov = l.strip().split()
        BIN_AVG_COV["Bin_" + bin] = cov
      avg_cov = BIN_AVG_COV[wildcards["bin"]]
      shell("""
            out=$(dirname {output})/simplif
            rm -rf $out
            mkdir -p $out/tmp
            in=$(dirname {input})
            for g in $in/*gfa; do
                name=$(basename $g .gfa)
                {SOFT}/spades-gsimplifier $g $out/$name --gfa -k {ASSEMBLY_K} -s $in/$name.stops -d $in/$name.deadends -p $in/$name.tsv -c {avg_cov} -read-length {READ_LENGTH} -t {threads} -tmpdir $out/tmp &> $out/$name.log
            done
            """)

#TODO check that simplification is not restarted for non-merged subgraphs!
def subgraphs_simplification_done(wildcards):
  checkpoints.fuse.get(bin_type=wildcards["bin_type"])
  return expand("{path}/simplif.done", path = bin_paths_by_type(wildcards["bin_type"]))
 
#TODO why 'fuse'? :)
checkpoint fuse:
    input : "subgraphs/{bin_type}/folder_done"
    output: touch("subgraphs/{bin_type}/fuse.done")

rule collect_bins_need_dereplication :
    input:   flag=get_list_subgraph_done
    output:  ignore="subgraphs/{bin_type}/List_bin_cogs_to_ignore.tsv",
             merge="subgraphs/{bin_type}/List_bin_to_merge.tsv"
    shell:   "{SCRIPTS}/Common_unitigs.py $(dirname {output.ignore})/'Bin*/simplif/COG*.gfa' 10 $(dirname {output.ignore})/"

#TODO review logic and maybe move to scripts / separate into multiple rules
#FIXME normalize variable names and spacing
checkpoint merge_bins:
    input:   "subgraphs/Bin_ini/List_bin_to_merge.tsv",
             "binning/clustering_gt%s_merged.csv" % MIN_CONTIG_SIZE
    output:  "subgraphs/Merged_Bin/clustering_gt%s_merged.csv" % MIN_CONTIG_SIZE,
              #TODO why do we need this flag?
              touch("subgraphs/Merged_Bin/folder_done")
    params: "subgraphs/Merged_Bin/"
    run:
        # merge and remove old bins
        all_bins = [os.path.basename(b) for b in INIT_BIN_PATHS]
        merged_bins = set()
        for line in open(input[0]) :
            split_line=line.rstrip().split("\t")
            name_new_bin = split_line[0]
            to_merge = split_line[1:]
            merged_bins |= set(to_merge)
            new_bin_path=os.path.join(params[0]), name_new_bin)
            os.system('mkdir -p ' + new_bin_path)
            All_bins_element=lambda text:" ".join([os.path.join(os.path.dirname(input[0]),bin,text) for bin in to_merge])
            os.system('cat '+All_bins_element("contigs.fa")+" > "+new_bin_path+"/contigs.fa")
            os.system('cat '+All_bins_element("SCG.fna")+" > "+new_bin_path+"/SCG.fna")
  
        # link all non merged bin in the merged bin folder
        for b in set(all_bins) - merged_bins:
            os.system("ln -s ../Bin_ini/"+b+" "+params[0]+"/")
  
        #TODO improve readability
        # create a new contig attribution file 
        Dico_bin_new_name={element.replace("Bin_",""):line.rstrip().split()[0].replace("Bin_","") for line in open(input[0]) for element in  line.rstrip().split()[1:]}
        #TODO add to inputs
        with open(output[0],"w") as out:
            for line in open(input[1]):
                contig,bins=line.rstrip().split(",")
                if bins in Dico_bin_new_name :
                    out.write(",".join([contig,Dico_bin_new_name[bins]])+"\n")
                else :
                    out.write(line)

#TODO remove by reusing another snakefile (as discussed with Seb)
rule compute_avg_cov_merged:
    input:   "subgraphs/Merged_Bin/clustering_gt%s_merged.csv" % MIN_CONTIG_SIZE
    output:  "subgraphs/Merged_Bin/bin_cov.tsv"
    shell:   "{SCRIPTS}/bin_cov.py {input} {output} {ASSEMBLY_K}"

rule flag_bad_cogs:
		#TODO remove List from file names
    input:  "{path}/List_bin_cogs_to_ignore.tsv",
            "{path}/{bin}/simplif.done"
    output:  touch("{path}/{bin}/List_cogs_selected.tsv")
    run:
         with open(input[0]) as cogs_to_ignore:
             for line in cogs_to_ignore:
                 split_line = line.rstrip().split("\t")
                 bin_name = split_line[0]
                 if bin_name == wildcards.bin:
                     bad_cogs = set()
                     if len(split_line) != 1:
                         bad_cogs = {cog for cog in split_line[1:]}
                 
                     cogs, = glob_wildcards(os.dirname(output[0]) + "/{cog}.gfa")
			     			     cogs = [cog for cog in cogs if cog not in bad_cogs]
                     with open(output[0], "w") as out:
                         out.write("\n".join(sorted(cogs)))

			   		 break

#TODO review logic
def merged_bin_cogs(wildcards):
    checkpoints.merge_bins.get(path="subgraphs")
    # since we linked non merged bins in the merged bin folder, bins in that folder are, at that point in time, the correct set of bin to consider. 
    return [binpath+"/List_cogs_selected.tsv" for binpath in bin_paths_by_type("Merged_Bin")]

rule select_bins_for_strain_analysis:
    input:  merged_bin_cogs
    output: "subgraphs/Merged_Bin/selected_bins.txt"
    message : "Select bins containing sufficient number of COGs"
    run:
      #FIXME magic constant
      # select bin_name only, not full path 
      bins = [os.path.basename(os.path.dirname(cogs_fn)) for cogs_fn in input \
              if len(list(open(selected_cogs_fn).readlines())) >= 10]
      with open(output[0], 'w') as out:
          out.write("\n".join(bins))
